{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Load the (same) athletes dataset.\n",
        "\n",
        "With your dataset use AutoML to find the best model (if it is no-code, submit screenshots).\n",
        "\n",
        "Report any data insights from AutoML run.\n",
        "\n",
        "What are the reported top 5 features?\n",
        "\n",
        "What are the top 3 models per validation score when using\n",
        "\n",
        "all features\n",
        "\n",
        "only the top features (if you have to choose a number put in 3)\n",
        "\n",
        "What are the top 3 models per speed when using\n",
        "\n",
        "all features\n",
        "\n",
        "only the top features (if you have to choose a number put in 3)\n",
        "\n",
        "How does the top models compare to your previously developed model (assignments 1 and 2) in terms of validation score and speed?\n",
        "\n",
        "Is your platform AutoML no-code/low-code/full-code and why?\n",
        "\n",
        "Repeat 2 - 5 using H2O AutoML (https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.htmlLinks to an external site.). Submit code."
      ],
      "metadata": {
        "id": "pTst7UdxmRBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### This notebook uses FLAML"
      ],
      "metadata": {
        "id": "Dp3oCwr0mcax"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used ChatGTP 4o to help me understand key concepts and debug codes."
      ],
      "metadata": {
        "id": "ZmC4td6u5ryk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the (same) athletes dataset."
      ],
      "metadata": {
        "id": "HJlJ7vQv-yzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdVeDQzdwTca",
        "outputId": "fbf47661-1b6b-4847-d5ae-5c01de7b9d2d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting flaml\n",
            "  Downloading FLAML-2.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.11/dist-packages (from flaml) (2.0.2)\n",
            "Downloading FLAML-2.3.5-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: flaml\n",
            "Successfully installed flaml-2.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar-dDpD_wUJ0",
        "outputId": "610fa829-3be8-44be-c404-a5b251429898"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check current working directory\n",
        "import os\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "b4waG0f_wrsH",
        "outputId": "d3d28875-4ab1-4577-bee6-9ae4178c8539"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive/ -name \"athletes_cleaned.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUsEQ8c_wvoi",
        "outputId": "b7d6697c-e2d0-43fc-e6e8-9e7b235b98cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML_OPS_Assignment3/athletes_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "athletes_df = pd.read_csv(\"/content/drive/MyDrive/ML_OPS_Assignment3/athletes_cleaned.csv\")\n",
        "athletes_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CcYgq5Pqwvl3",
        "outputId": "b67430cb-aa80-407d-9f63-5dd0cc0928a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   athlete_id            name               region               affiliate  \\\n",
              "0     21269.0    Erik Acevedo  Southern California  CrossFit Training Yard   \n",
              "1     21685.0  Richard Ablett               Africa           Cape CrossFit   \n",
              "2     25464.0     Joe Abruzzo           North East        CrossFit Rapture   \n",
              "3     43767.0  Brigham Abbott        North Central    River North CrossFit   \n",
              "4     55504.0  Jason Ackerman           North East      CrossFit Soulshine   \n",
              "\n",
              "  gender   age  height  weight  \\\n",
              "0   Male  30.0    71.0   200.0   \n",
              "1   Male  28.0    70.0   176.0   \n",
              "2   Male  35.0    68.0   225.0   \n",
              "3   Male  36.0    71.0   199.0   \n",
              "4   Male  36.0    64.0   155.0   \n",
              "\n",
              "                                                 eat  \\\n",
              "0                      I eat whatever is convenient|   \n",
              "1               I eat 1-3 full cheat meals per week|   \n",
              "2  I eat quality foods but don't measure the amount|   \n",
              "3  I eat quality foods but don't measure the amount|   \n",
              "4                                I eat strict Paleo|   \n",
              "\n",
              "                                               train              background  \\\n",
              "0  I workout mostly at a CrossFit Affiliate|I inc...          College sports   \n",
              "1          I workout mostly at a CrossFit Affiliate|  No athletic background   \n",
              "2  I workout mostly at a CrossFit Affiliate|I rec...                   Other   \n",
              "3  I workout mostly at a CrossFit Affiliate|I hav...          College sports   \n",
              "4  I workout mostly at home, work, or a tradition...          College sports   \n",
              "\n",
              "      howlong  total_lift  \n",
              "0  1-2 years|      1110.0  \n",
              "1  2-4 years|       910.0  \n",
              "2  2-4 years|      1335.0  \n",
              "3  1-2 years|      1354.0  \n",
              "4   4+ years|      1225.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c069314a-0d12-4a67-a84d-f6de0e8b268e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>athlete_id</th>\n",
              "      <th>name</th>\n",
              "      <th>region</th>\n",
              "      <th>affiliate</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>height</th>\n",
              "      <th>weight</th>\n",
              "      <th>eat</th>\n",
              "      <th>train</th>\n",
              "      <th>background</th>\n",
              "      <th>howlong</th>\n",
              "      <th>total_lift</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21269.0</td>\n",
              "      <td>Erik Acevedo</td>\n",
              "      <td>Southern California</td>\n",
              "      <td>CrossFit Training Yard</td>\n",
              "      <td>Male</td>\n",
              "      <td>30.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>I eat whatever is convenient|</td>\n",
              "      <td>I workout mostly at a CrossFit Affiliate|I inc...</td>\n",
              "      <td>College sports</td>\n",
              "      <td>1-2 years|</td>\n",
              "      <td>1110.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21685.0</td>\n",
              "      <td>Richard Ablett</td>\n",
              "      <td>Africa</td>\n",
              "      <td>Cape CrossFit</td>\n",
              "      <td>Male</td>\n",
              "      <td>28.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>I eat 1-3 full cheat meals per week|</td>\n",
              "      <td>I workout mostly at a CrossFit Affiliate|</td>\n",
              "      <td>No athletic background</td>\n",
              "      <td>2-4 years|</td>\n",
              "      <td>910.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25464.0</td>\n",
              "      <td>Joe Abruzzo</td>\n",
              "      <td>North East</td>\n",
              "      <td>CrossFit Rapture</td>\n",
              "      <td>Male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>I eat quality foods but don't measure the amount|</td>\n",
              "      <td>I workout mostly at a CrossFit Affiliate|I rec...</td>\n",
              "      <td>Other</td>\n",
              "      <td>2-4 years|</td>\n",
              "      <td>1335.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>43767.0</td>\n",
              "      <td>Brigham Abbott</td>\n",
              "      <td>North Central</td>\n",
              "      <td>River North CrossFit</td>\n",
              "      <td>Male</td>\n",
              "      <td>36.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>199.0</td>\n",
              "      <td>I eat quality foods but don't measure the amount|</td>\n",
              "      <td>I workout mostly at a CrossFit Affiliate|I hav...</td>\n",
              "      <td>College sports</td>\n",
              "      <td>1-2 years|</td>\n",
              "      <td>1354.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>55504.0</td>\n",
              "      <td>Jason Ackerman</td>\n",
              "      <td>North East</td>\n",
              "      <td>CrossFit Soulshine</td>\n",
              "      <td>Male</td>\n",
              "      <td>36.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>155.0</td>\n",
              "      <td>I eat strict Paleo|</td>\n",
              "      <td>I workout mostly at home, work, or a tradition...</td>\n",
              "      <td>College sports</td>\n",
              "      <td>4+ years|</td>\n",
              "      <td>1225.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c069314a-0d12-4a67-a84d-f6de0e8b268e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c069314a-0d12-4a67-a84d-f6de0e8b268e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c069314a-0d12-4a67-a84d-f6de0e8b268e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f9ca1986-7925-4cbb-83a6-3662dde08578\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f9ca1986-7925-4cbb-83a6-3662dde08578')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f9ca1986-7925-4cbb-83a6-3662dde08578 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "athletes_df",
              "summary": "{\n  \"name\": \"athletes_df\",\n  \"rows\": 30015,\n  \"fields\": [\n    {\n      \"column\": \"athlete_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 166073.24888422387,\n        \"min\": 84.0,\n        \"max\": 630117.0,\n        \"num_unique_values\": 30015,\n        \"samples\": [\n          109090.0,\n          264274.0,\n          176742.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29533,\n        \"samples\": [\n          \"Pascha Brim\",\n          \"Kelly Dillon\",\n          \"Kasey Heil\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Southern California\",\n          \"Africa\",\n          \"South Central\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"affiliate\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 7244,\n        \"samples\": [\n          \"CrossFit Warrior Spirit\",\n          \"Reebok CrossFit Liberty Village\",\n          \"CrossFit For Fitness\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gender\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Female\",\n          \"Male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.436255356166137,\n        \"min\": 18.0,\n        \"max\": 56.0,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          51.0,\n          53.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"height\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7748086869153203,\n        \"min\": 52.0,\n        \"max\": 83.0,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          59.0,\n          65.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weight\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.397735423440345,\n        \"min\": 5.0,\n        \"max\": 474.0,\n        \"num_unique_values\": 274,\n        \"samples\": [\n          194.0,\n          69.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eat\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 40,\n        \"samples\": [\n          \"I weigh and measure my food|I eat strict Paleo|I eat quality foods but don't measure the amount|\",\n          \"I eat strict Paleo|I eat quality foods but don't measure the amount|I eat whatever is convenient|\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"train\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 72,\n        \"samples\": [\n          \"I workout mostly at home, work, or a traditional gym|I incorporate CrossFit.com workouts|I record my workouts|\",\n          \"I workout mostly at a CrossFit Affiliate|I have a coach who determines my programming|I incorporate CrossFit.com workouts|I write my own programming|Decline to answer|\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"background\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"No athletic background\",\n          \"Professional sports\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"howlong\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"6-12 months|1-2 years|\",\n          \"1-2 years|2-4 years|4+ years|\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_lift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 277.5797931259734,\n        \"min\": 4.0,\n        \"max\": 2135.0,\n        \"num_unique_values\": 1286,\n        \"samples\": [\n          313.0,\n          1564.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "athletes_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoZKi4qAwvhj",
        "outputId": "30ab65ed-24af-4134-d4a1-faf482d781a6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30015 entries, 0 to 30014\n",
            "Data columns (total 13 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   athlete_id  30015 non-null  float64\n",
            " 1   name        30015 non-null  object \n",
            " 2   region      30015 non-null  object \n",
            " 3   affiliate   29062 non-null  object \n",
            " 4   gender      30015 non-null  object \n",
            " 5   age         30015 non-null  float64\n",
            " 6   height      30015 non-null  float64\n",
            " 7   weight      30015 non-null  float64\n",
            " 8   eat         30015 non-null  object \n",
            " 9   train       30015 non-null  object \n",
            " 10  background  30015 non-null  object \n",
            " 11  howlong     30015 non-null  object \n",
            " 12  total_lift  30015 non-null  float64\n",
            "dtypes: float64(5), object(8)\n",
            "memory usage: 3.0+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categoricals\n",
        "for col in athletes_df.select_dtypes(include=\"object\").columns:\n",
        "    athletes_df[col] = athletes_df[col].astype(\"category\")"
      ],
      "metadata": {
        "id": "uvpOH_6JxftV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "athletes_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onMSaAYNylX_",
        "outputId": "4d789a06-6099-4b91-cfeb-b1add78f0814"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 30015 entries, 0 to 30014\n",
            "Data columns (total 13 columns):\n",
            " #   Column      Non-Null Count  Dtype   \n",
            "---  ------      --------------  -----   \n",
            " 0   athlete_id  30015 non-null  float64 \n",
            " 1   name        30015 non-null  category\n",
            " 2   region      30015 non-null  category\n",
            " 3   affiliate   29062 non-null  category\n",
            " 4   gender      30015 non-null  category\n",
            " 5   age         30015 non-null  float64 \n",
            " 6   height      30015 non-null  float64 \n",
            " 7   weight      30015 non-null  float64 \n",
            " 8   eat         30015 non-null  category\n",
            " 9   train       30015 non-null  category\n",
            " 10  background  30015 non-null  category\n",
            " 11  howlong     30015 non-null  category\n",
            " 12  total_lift  30015 non-null  float64 \n",
            "dtypes: category(8), float64(5)\n",
            "memory usage: 3.0 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With your dataset use AutoML to find the best model"
      ],
      "metadata": {
        "id": "uJgWHBwN-vtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = athletes_df.drop(columns=[\"total_lift\"])\n",
        "y = athletes_df[\"total_lift\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "xQSA3xMYyngF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.24.3 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "AK79XK-D0LJq",
        "outputId": "c1510394-20ee-4ae5-ef69-1245479197f5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.24.3\n",
            "  Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Downloading numpy-1.24.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\n",
            "jaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\n",
            "jax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\n",
            "blosc2 3.5.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "05d30d5fa6fe4e5c8dada3f75aec3056"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flaml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JziA3P70RMX",
        "outputId": "4442a4c2-0ad6-4a00-c3d5-40b58085e6c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flaml in /usr/local/lib/python3.11/dist-packages (2.3.5)\n",
            "Requirement already satisfied: NumPy>=1.17 in /usr/local/lib/python3.11/dist-packages (from flaml) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flaml import AutoML"
      ],
      "metadata": {
        "id": "0k5c3g7N0W2J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoML(): creates the AutoML engine\n",
        "\n",
        "time_budget=600: runs for up to 10 minutes\n",
        "\n",
        "metric=\"rmse\": optimizes for Root Mean Squared Error\n",
        "\n",
        "task=\"regression\": predicts a numeric target (total_lift)\n",
        "\n",
        "automl.fit(...): trains multiple models on X_train, selects the best one automatically.\n",
        "\n",
        "FLAML trains each model (e.g., lgbm, xgboost, etc.) using all features from X_train\n",
        "\n",
        "It then tunes hyperparameters (like learning rate, tree depth, etc.) to minimize my chosen metric (rmse)\n",
        "\n",
        "FLAML will select the model that achieves the lowest RMSE on validation data during training.\n",
        "\n",
        "FLAML uses internal cross-validation (or a hold-out validation split) on training set (X_train, y_train) to estimate model performance. This is:\n",
        "\n",
        "not the final X_test test set,\n",
        "\n",
        "instead, it's validation scores calculated during the AutoML search process.\n",
        "\n",
        "That means:\n",
        "\n",
        "The best model is selected based on the lowest RMSE on validation data, not test data."
      ],
      "metadata": {
        "id": "Fzjns8c-0f9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FLAML AutoML\n",
        "\n",
        "automl = AutoML()\n",
        "\n",
        "automl_settings = {\n",
        "    \"metric\": \"rmse\",                            # Optimization metric\n",
        "    'estimator_list': ['lgbm', 'xgboost', 'rf'], # Limit AutoML to these 3 fast and strong regressors\n",
        "    \"task\": \"regression\",                        # Task type\n",
        "    \"log_file_name\": \"flaml_automl.log\",         # Where to store training logs\n",
        "    \"max_iter\": 40                               # limits the total number of trials (i.e., models)\n",
        "}\n",
        "\n",
        "automl.fit(X_train=X_train, y_train=y_train, **automl_settings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOk8VH0CywAy",
        "outputId": "34b997ab-d3aa-407c-932a-3f02331e9d00"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 07-19 22:11:50] {1752} INFO - task = regression\n",
            "[flaml.automl.logger: 07-19 22:11:50] {1763} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 07-19 22:11:50] {1862} INFO - Minimizing error metric: rmse\n",
            "[flaml.automl.logger: 07-19 22:11:50] {1979} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'rf']\n",
            "[flaml.automl.logger: 07-19 22:11:50] {2282} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:50] {2417} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.\n",
            "[flaml.automl.logger: 07-19 22:11:50] {2466} INFO -  at 0.5s,\testimator lgbm's best error=226.1395,\tbest estimator lgbm's best error=226.1395\n",
            "[flaml.automl.logger: 07-19 22:11:50] {2282} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:51] {2466} INFO -  at 1.0s,\testimator lgbm's best error=226.1395,\tbest estimator lgbm's best error=226.1395\n",
            "[flaml.automl.logger: 07-19 22:11:51] {2282} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:51] {2466} INFO -  at 1.5s,\testimator lgbm's best error=184.0747,\tbest estimator lgbm's best error=184.0747\n",
            "[flaml.automl.logger: 07-19 22:11:51] {2282} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:11:51] {2466} INFO -  at 1.8s,\testimator xgboost's best error=226.1443,\tbest estimator lgbm's best error=184.0747\n",
            "[flaml.automl.logger: 07-19 22:11:51] {2282} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:52] {2466} INFO -  at 2.3s,\testimator lgbm's best error=148.4558,\tbest estimator lgbm's best error=148.4558\n",
            "[flaml.automl.logger: 07-19 22:11:52] {2282} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:52] {2466} INFO -  at 2.7s,\testimator lgbm's best error=148.4558,\tbest estimator lgbm's best error=148.4558\n",
            "[flaml.automl.logger: 07-19 22:11:52] {2282} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:53] {2466} INFO -  at 3.3s,\testimator lgbm's best error=146.3184,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:53] {2282} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:53] {2466} INFO -  at 3.8s,\testimator lgbm's best error=146.3184,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:53] {2282} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:11:55] {2466} INFO -  at 4.9s,\testimator lgbm's best error=146.3184,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:55] {2282} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:11:56] {2466} INFO -  at 6.4s,\testimator xgboost's best error=226.1443,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:56] {2282} INFO - iteration 10, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:11:57] {2466} INFO -  at 7.4s,\testimator rf's best error=178.1796,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:57] {2282} INFO - iteration 11, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:11:57] {2466} INFO -  at 7.7s,\testimator xgboost's best error=185.5242,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:57] {2282} INFO - iteration 12, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:11:58] {2466} INFO -  at 8.6s,\testimator rf's best error=159.2518,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:58] {2282} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:11:59] {2466} INFO -  at 8.9s,\testimator xgboost's best error=160.8563,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:59] {2282} INFO - iteration 14, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:11:59] {2466} INFO -  at 9.6s,\testimator rf's best error=159.2518,\tbest estimator lgbm's best error=146.3184\n",
            "[flaml.automl.logger: 07-19 22:11:59] {2282} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:00] {2466} INFO -  at 10.3s,\testimator lgbm's best error=140.5913,\tbest estimator lgbm's best error=140.5913\n",
            "[flaml.automl.logger: 07-19 22:12:00] {2282} INFO - iteration 16, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:12:02] {2466} INFO -  at 12.0s,\testimator rf's best error=152.0328,\tbest estimator lgbm's best error=140.5913\n",
            "[flaml.automl.logger: 07-19 22:12:02] {2282} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:02] {2466} INFO -  at 12.5s,\testimator lgbm's best error=140.5913,\tbest estimator lgbm's best error=140.5913\n",
            "[flaml.automl.logger: 07-19 22:12:02] {2282} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:12:02] {2466} INFO -  at 12.9s,\testimator xgboost's best error=160.8563,\tbest estimator lgbm's best error=140.5913\n",
            "[flaml.automl.logger: 07-19 22:12:02] {2282} INFO - iteration 19, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:04] {2466} INFO -  at 14.6s,\testimator lgbm's best error=139.3918,\tbest estimator lgbm's best error=139.3918\n",
            "[flaml.automl.logger: 07-19 22:12:04] {2282} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:12:05] {2466} INFO -  at 14.9s,\testimator xgboost's best error=160.8563,\tbest estimator lgbm's best error=139.3918\n",
            "[flaml.automl.logger: 07-19 22:12:05] {2282} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:07] {2466} INFO -  at 17.2s,\testimator lgbm's best error=139.3918,\tbest estimator lgbm's best error=139.3918\n",
            "[flaml.automl.logger: 07-19 22:12:07] {2282} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:11] {2466} INFO -  at 21.6s,\testimator lgbm's best error=139.3918,\tbest estimator lgbm's best error=139.3918\n",
            "[flaml.automl.logger: 07-19 22:12:11] {2282} INFO - iteration 23, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:12:12] {2466} INFO -  at 21.9s,\testimator xgboost's best error=150.7174,\tbest estimator lgbm's best error=139.3918\n",
            "[flaml.automl.logger: 07-19 22:12:12] {2282} INFO - iteration 24, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:12:13] {2466} INFO -  at 23.6s,\testimator rf's best error=148.3598,\tbest estimator lgbm's best error=139.3918\n",
            "[flaml.automl.logger: 07-19 22:12:13] {2282} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:15] {2466} INFO -  at 25.3s,\testimator lgbm's best error=139.3732,\tbest estimator lgbm's best error=139.3732\n",
            "[flaml.automl.logger: 07-19 22:12:15] {2282} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:12:15] {2466} INFO -  at 25.7s,\testimator xgboost's best error=146.1094,\tbest estimator lgbm's best error=139.3732\n",
            "[flaml.automl.logger: 07-19 22:12:15] {2282} INFO - iteration 27, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:12:17] {2466} INFO -  at 27.5s,\testimator rf's best error=148.3598,\tbest estimator lgbm's best error=139.3732\n",
            "[flaml.automl.logger: 07-19 22:12:17] {2282} INFO - iteration 28, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:12:19] {2466} INFO -  at 29.2s,\testimator rf's best error=148.0126,\tbest estimator lgbm's best error=139.3732\n",
            "[flaml.automl.logger: 07-19 22:12:19] {2282} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:23] {2466} INFO -  at 33.7s,\testimator lgbm's best error=139.0508,\tbest estimator lgbm's best error=139.0508\n",
            "[flaml.automl.logger: 07-19 22:12:23] {2282} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:26] {2466} INFO -  at 36.1s,\testimator lgbm's best error=139.0508,\tbest estimator lgbm's best error=139.0508\n",
            "[flaml.automl.logger: 07-19 22:12:26] {2282} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:27] {2466} INFO -  at 37.7s,\testimator lgbm's best error=139.0508,\tbest estimator lgbm's best error=139.0508\n",
            "[flaml.automl.logger: 07-19 22:12:27] {2282} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:12:28] {2466} INFO -  at 38.1s,\testimator xgboost's best error=146.1094,\tbest estimator lgbm's best error=139.0508\n",
            "[flaml.automl.logger: 07-19 22:12:28] {2282} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:30] {2466} INFO -  at 40.4s,\testimator lgbm's best error=139.0508,\tbest estimator lgbm's best error=139.0508\n",
            "[flaml.automl.logger: 07-19 22:12:30] {2282} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:32] {2466} INFO -  at 42.2s,\testimator lgbm's best error=138.6097,\tbest estimator lgbm's best error=138.6097\n",
            "[flaml.automl.logger: 07-19 22:12:32] {2282} INFO - iteration 35, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:12:32] {2466} INFO -  at 42.7s,\testimator xgboost's best error=144.5356,\tbest estimator lgbm's best error=138.6097\n",
            "[flaml.automl.logger: 07-19 22:12:32] {2282} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:33] {2466} INFO -  at 43.8s,\testimator lgbm's best error=138.6097,\tbest estimator lgbm's best error=138.6097\n",
            "[flaml.automl.logger: 07-19 22:12:33] {2282} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:39] {2466} INFO -  at 49.8s,\testimator lgbm's best error=137.9810,\tbest estimator lgbm's best error=137.9810\n",
            "[flaml.automl.logger: 07-19 22:12:39] {2282} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:44] {2466} INFO -  at 54.8s,\testimator lgbm's best error=137.9810,\tbest estimator lgbm's best error=137.9810\n",
            "[flaml.automl.logger: 07-19 22:12:44] {2282} INFO - iteration 39, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:12:50] {2466} INFO -  at 60.3s,\testimator lgbm's best error=137.8859,\tbest estimator lgbm's best error=137.8859\n",
            "[flaml.automl.logger: 07-19 22:12:50] {2724} INFO - retrain lgbm for 0.5s\n",
            "[flaml.automl.logger: 07-19 22:12:50] {2727} INFO - retrained model: LGBMRegressor(colsample_bytree=0.38626024040974977,\n",
            "              learning_rate=0.05196155644285028, max_bin=31,\n",
            "              min_child_samples=9, n_estimators=288, n_jobs=-1, num_leaves=19,\n",
            "              reg_alpha=0.0016471893565638506, reg_lambda=0.002581620911069276,\n",
            "              verbose=-1)\n",
            "[flaml.automl.logger: 07-19 22:12:50] {2009} INFO - fit succeeded\n",
            "[flaml.automl.logger: 07-19 22:12:50] {2010} INFO - Time taken to find the best model: 60.33635425567627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best model from FLAML**: **LightGBM (lgbm)**\n",
        "**Best validation RMSE**: **137.89**\n",
        "**Time taken**: **\\~60.3 seconds**\n",
        "**Final model config**: 288 estimators, 19 leaves, learning rate ≈ 0.052, etc."
      ],
      "metadata": {
        "id": "G9gmvtWl4Ruq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install \"flaml[notebook]\""
      ],
      "metadata": {
        "id": "sNgSNtKOywi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report any data insights from AutoML run."
      ],
      "metadata": {
        "id": "MJIHF78Z-nso"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best model and its parameters\n",
        "print(\"Best model type:\", automl.best_estimator)\n",
        "print(\"Best hyperparameters:\", automl.best_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc0WrcnL5u8J",
        "outputId": "949adbdb-51e4-4e3e-c1ff-f9b290ed04a9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model type: lgbm\n",
            "Best hyperparameters: {'n_estimators': 288, 'num_leaves': 19, 'min_child_samples': 9, 'learning_rate': 0.05196155644285028, 'log_max_bin': 5, 'colsample_bytree': 0.38626024040974977, 'reg_alpha': 0.0016471893565638506, 'reg_lambda': 0.002581620911069276}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = automl.predict(X_test)\n",
        "\n",
        "# Manually calculate RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"Test RMSE:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R57mNyfJ9bzB",
        "outputId": "3c483a82-04ed-4731-a972-7a3d8ae88cca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 139.17101323933082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What are the reported top 5 features?\n",
        "\n",
        "howlong, train, eat, background, age"
      ],
      "metadata": {
        "id": "RqKNOHEX-lWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The most important 5 features reported by the best model found by FLAML\n",
        "import pandas as pd\n",
        "\n",
        "# Get best estimator\n",
        "best_model = automl.model\n",
        "\n",
        "# Create DataFrame of feature importances\n",
        "feature_importances = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': best_model.feature_importances_\n",
        "}).sort_values(by='importance', ascending=False)\n",
        "\n",
        "# Display top 5 features\n",
        "top5 = feature_importances.head(5)\n",
        "print(top5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZrx3xQBEBbS",
        "outputId": "d3761c4e-4f4d-4292-e451-ee37e38df86d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       feature  importance\n",
            "11     howlong        1154\n",
            "9        train         715\n",
            "8          eat         648\n",
            "10  background         563\n",
            "5          age         492\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top 3 models per validation score using all features"
      ],
      "metadata": {
        "id": "1GWhZYqH-7wb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read log lines\n",
        "with open(\"flaml_automl.log\", \"r\") as file:\n",
        "    log_lines = file.readlines()\n",
        "\n",
        "# Parse model entries\n",
        "data = []\n",
        "configs = []\n",
        "for line in log_lines:\n",
        "    try:\n",
        "        record = json.loads(line)\n",
        "        if \"validation_loss\" in record and \"learner\" in record:\n",
        "            learner = record[\"learner\"]\n",
        "            val_loss = record[\"validation_loss\"]\n",
        "            time = record.get(\"wall_clock_time\", None)\n",
        "            config = record.get(\"config\", {})\n",
        "            data.append((learner, val_loss, time, config))\n",
        "    except json.JSONDecodeError:\n",
        "        continue\n",
        "\n",
        "# Create DataFrame\n",
        "df_trials = pd.DataFrame(data, columns=[\"learner\", \"val_loss\", \"wall_clock_time\", \"config\"])\n",
        "\n",
        "# Get top 3 by validation loss\n",
        "top3 = df_trials.sort_values(by=\"val_loss\").head(3)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 3 models by validation RMSE with configs:\")\n",
        "for idx, row in top3.iterrows():\n",
        "    print(f\"\\nLearner: {row['learner']}\")\n",
        "    print(f\"Val Loss (RMSE): {row['val_loss']}\")\n",
        "    print(f\"Wall Clock Time: {row['wall_clock_time']}\")\n",
        "    print(\"Config:\")\n",
        "    for k, v in row['config'].items():\n",
        "        print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmzYjaQ5EfrY",
        "outputId": "9632b435-0d8d-4a9f-ff7b-6f64ada5a3bb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 models by validation RMSE with configs:\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 137.88590673968528\n",
            "Wall Clock Time: 60.33635425567627\n",
            "Config:\n",
            "  n_estimators: 288\n",
            "  num_leaves: 19\n",
            "  min_child_samples: 9\n",
            "  learning_rate: 0.05196155644285028\n",
            "  log_max_bin: 5\n",
            "  colsample_bytree: 0.38626024040974977\n",
            "  reg_alpha: 0.0016471893565638506\n",
            "  reg_lambda: 0.002581620911069276\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 137.98097414912297\n",
            "Wall Clock Time: 49.810667514801025\n",
            "Config:\n",
            "  n_estimators: 561\n",
            "  num_leaves: 9\n",
            "  min_child_samples: 4\n",
            "  learning_rate: 0.06419203531794242\n",
            "  log_max_bin: 5\n",
            "  colsample_bytree: 0.43644825283873734\n",
            "  reg_alpha: 0.007721515950790995\n",
            "  reg_lambda: 0.005535643981633633\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 138.60969463147686\n",
            "Wall Clock Time: 42.2374746799469\n",
            "Config:\n",
            "  n_estimators: 273\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 5\n",
            "  learning_rate: 0.19785013601703466\n",
            "  log_max_bin: 6\n",
            "  colsample_bytree: 0.5834987745562512\n",
            "  reg_alpha: 0.012306726057063571\n",
            "  reg_lambda: 0.0036001076881759493\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top 3 models per validation score using only the top features\n"
      ],
      "metadata": {
        "id": "GMchyLqAGe-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a reduced dataset using only these top 3 features\n",
        "top3_features = ['howlong', 'train', 'eat']\n",
        "X_train_top3 = X_train[top3_features]\n",
        "X_test_top3 = X_test[top3_features]"
      ],
      "metadata": {
        "id": "CjzmzmzaaT6Y"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run FLAML AutoML\n",
        "\n",
        "automl = AutoML()\n",
        "\n",
        "automl_settings = {\n",
        "    \"metric\": \"rmse\",                            # Optimization metric\n",
        "    'estimator_list': ['lgbm', 'xgboost', 'rf'], # Limit AutoML to these 3 fast and strong regressors\n",
        "    \"task\": \"regression\",                        # Task type\n",
        "    \"log_file_name\": \"flaml_automl_top3.log\",    # Where to store training logs\n",
        "    \"max_iter\": 40                               # limits the total number of trials (i.e., models)\n",
        "}\n",
        "\n",
        "automl.fit(X_train=X_train_top3, y_train=y_train, **automl_settings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11JoUpGPazYf",
        "outputId": "9d51bdd4-6d5a-4ab6-d624-bdc3678c9477"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[flaml.automl.logger: 07-19 22:13:40] {1752} INFO - task = regression\n",
            "[flaml.automl.logger: 07-19 22:13:40] {1763} INFO - Evaluation method: cv\n",
            "[flaml.automl.logger: 07-19 22:13:40] {1862} INFO - Minimizing error metric: rmse\n",
            "[flaml.automl.logger: 07-19 22:13:40] {1979} INFO - List of ML learners in AutoML Run: ['lgbm', 'xgboost', 'rf']\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2282} INFO - iteration 0, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2417} INFO - Estimated sufficient time budget=10000s. Estimated necessary time budget=10s.\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2466} INFO -  at 0.1s,\testimator lgbm's best error=268.1706,\tbest estimator lgbm's best error=268.1706\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2282} INFO - iteration 1, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2466} INFO -  at 0.3s,\testimator lgbm's best error=268.1706,\tbest estimator lgbm's best error=268.1706\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2282} INFO - iteration 2, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2466} INFO -  at 0.4s,\testimator lgbm's best error=261.5318,\tbest estimator lgbm's best error=261.5318\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2282} INFO - iteration 3, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2466} INFO -  at 0.6s,\testimator xgboost's best error=270.8217,\tbest estimator lgbm's best error=261.5318\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2282} INFO - iteration 4, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2466} INFO -  at 0.7s,\testimator lgbm's best error=257.1304,\tbest estimator lgbm's best error=257.1304\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2282} INFO - iteration 5, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2466} INFO -  at 0.9s,\testimator lgbm's best error=257.1304,\tbest estimator lgbm's best error=257.1304\n",
            "[flaml.automl.logger: 07-19 22:13:40] {2282} INFO - iteration 6, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2466} INFO -  at 1.0s,\testimator lgbm's best error=257.0689,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2282} INFO - iteration 7, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2466} INFO -  at 1.2s,\testimator lgbm's best error=257.0689,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2282} INFO - iteration 8, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2466} INFO -  at 1.3s,\testimator lgbm's best error=257.0689,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2282} INFO - iteration 9, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2466} INFO -  at 1.5s,\testimator xgboost's best error=270.8217,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2282} INFO - iteration 10, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2466} INFO -  at 1.6s,\testimator xgboost's best error=265.9712,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:41] {2282} INFO - iteration 11, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2466} INFO -  at 1.9s,\testimator rf's best error=265.5730,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2282} INFO - iteration 12, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2466} INFO -  at 2.2s,\testimator rf's best error=260.3168,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2282} INFO - iteration 13, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2466} INFO -  at 2.3s,\testimator xgboost's best error=258.6492,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2282} INFO - iteration 14, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2466} INFO -  at 2.6s,\testimator rf's best error=260.3168,\tbest estimator lgbm's best error=257.0689\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2282} INFO - iteration 15, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2466} INFO -  at 2.9s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:42] {2282} INFO - iteration 16, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2466} INFO -  at 3.2s,\testimator rf's best error=258.3688,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2282} INFO - iteration 17, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2466} INFO -  at 3.4s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2282} INFO - iteration 18, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2466} INFO -  at 3.6s,\testimator xgboost's best error=258.6492,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2282} INFO - iteration 19, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2466} INFO -  at 3.7s,\testimator xgboost's best error=258.6492,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2282} INFO - iteration 20, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:43] {2466} INFO -  at 3.9s,\testimator xgboost's best error=257.8163,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:44] {2282} INFO - iteration 21, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:45] {2466} INFO -  at 5.1s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:45] {2282} INFO - iteration 22, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:45] {2466} INFO -  at 5.4s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:45] {2282} INFO - iteration 23, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:45] {2466} INFO -  at 5.8s,\testimator rf's best error=258.3688,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:45] {2282} INFO - iteration 24, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:46] {2466} INFO -  at 6.2s,\testimator rf's best error=258.3688,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:46] {2282} INFO - iteration 25, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:46] {2466} INFO -  at 6.4s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:46] {2282} INFO - iteration 26, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:46] {2466} INFO -  at 6.6s,\testimator xgboost's best error=257.7207,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:46] {2282} INFO - iteration 27, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2466} INFO -  at 7.0s,\testimator rf's best error=258.2312,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2282} INFO - iteration 28, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2466} INFO -  at 7.2s,\testimator xgboost's best error=257.7207,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2282} INFO - iteration 29, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2466} INFO -  at 7.6s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2282} INFO - iteration 30, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2466} INFO -  at 7.9s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:47] {2282} INFO - iteration 31, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:48] {2466} INFO -  at 8.2s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:48] {2282} INFO - iteration 32, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:48] {2466} INFO -  at 8.5s,\testimator xgboost's best error=257.6469,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:48] {2282} INFO - iteration 33, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:48] {2466} INFO -  at 8.8s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:48] {2282} INFO - iteration 34, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:49] {2466} INFO -  at 9.2s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:49] {2282} INFO - iteration 35, current learner rf\n",
            "[flaml.automl.logger: 07-19 22:13:50] {2466} INFO -  at 10.2s,\testimator rf's best error=258.2312,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:50] {2282} INFO - iteration 36, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:52] {2466} INFO -  at 12.5s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:52] {2282} INFO - iteration 37, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:52] {2466} INFO -  at 12.7s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:52] {2282} INFO - iteration 38, current learner lgbm\n",
            "[flaml.automl.logger: 07-19 22:13:53] {2466} INFO -  at 13.2s,\testimator lgbm's best error=256.9902,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:53] {2282} INFO - iteration 39, current learner xgboost\n",
            "[flaml.automl.logger: 07-19 22:13:53] {2466} INFO -  at 13.5s,\testimator xgboost's best error=257.5388,\tbest estimator lgbm's best error=256.9902\n",
            "[flaml.automl.logger: 07-19 22:13:53] {2724} INFO - retrain lgbm for 0.0s\n",
            "[flaml.automl.logger: 07-19 22:13:53] {2727} INFO - retrained model: LGBMRegressor(colsample_bytree=0.7610534336273627,\n",
            "              learning_rate=0.41929025492645006, max_bin=255,\n",
            "              min_child_samples=4, n_estimators=47, n_jobs=-1, num_leaves=4,\n",
            "              reg_alpha=0.0009765625, reg_lambda=0.009280655005879927,\n",
            "              verbose=-1)\n",
            "[flaml.automl.logger: 07-19 22:13:53] {2009} INFO - fit succeeded\n",
            "[flaml.automl.logger: 07-19 22:13:53] {2010} INFO - Time taken to find the best model: 2.866394281387329\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read log lines\n",
        "with open(\"flaml_automl_top3.log\", \"r\") as file:\n",
        "    log_lines = file.readlines()\n",
        "\n",
        "# Parse model entries\n",
        "data = []\n",
        "configs = []\n",
        "for line in log_lines:\n",
        "    try:\n",
        "        record = json.loads(line)\n",
        "        if \"validation_loss\" in record and \"learner\" in record:\n",
        "            learner = record[\"learner\"]\n",
        "            val_loss = record[\"validation_loss\"]\n",
        "            time = record.get(\"wall_clock_time\", None)\n",
        "            config = record.get(\"config\", {})\n",
        "            data.append((learner, val_loss, time, config))\n",
        "    except json.JSONDecodeError:\n",
        "        continue\n",
        "\n",
        "# Create DataFrame\n",
        "df_trials = pd.DataFrame(data, columns=[\"learner\", \"val_loss\", \"wall_clock_time\", \"config\"])\n",
        "\n",
        "# Get top 3 by validation loss\n",
        "top3 = df_trials.sort_values(by=\"val_loss\").head(3)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 3 models by validation RMSE with config using only the top 3 features:\")\n",
        "for idx, row in top3.iterrows():\n",
        "    print(f\"\\nLearner: {row['learner']}\")\n",
        "    print(f\"Val Loss (RMSE): {row['val_loss']}\")\n",
        "    print(f\"Wall Clock Time: {row['wall_clock_time']}\")\n",
        "    print(\"Config:\")\n",
        "    for k, v in row['config'].items():\n",
        "        print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRKbk7vgazVq",
        "outputId": "04428dc0-64b9-4ced-b42a-c37553da94a8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 models by validation RMSE with config using only the top 3 features:\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 256.99020140483015\n",
            "Wall Clock Time: 2.866394281387329\n",
            "Config:\n",
            "  n_estimators: 47\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 4\n",
            "  learning_rate: 0.41929025492645006\n",
            "  log_max_bin: 8\n",
            "  colsample_bytree: 0.7610534336273627\n",
            "  reg_alpha: 0.0009765625\n",
            "  reg_lambda: 0.009280655005879927\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 257.0689173821486\n",
            "Wall Clock Time: 1.0220036506652832\n",
            "Config:\n",
            "  n_estimators: 13\n",
            "  num_leaves: 5\n",
            "  min_child_samples: 5\n",
            "  learning_rate: 0.7590459488450945\n",
            "  log_max_bin: 8\n",
            "  colsample_bytree: 0.8304072431299575\n",
            "  reg_alpha: 0.001951378031519758\n",
            "  reg_lambda: 0.04792552866398477\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 257.1304090799774\n",
            "Wall Clock Time: 0.7351562976837158\n",
            "Config:\n",
            "  n_estimators: 11\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 9\n",
            "  learning_rate: 0.7260594590615893\n",
            "  log_max_bin: 9\n",
            "  colsample_bytree: 0.9285002286474459\n",
            "  reg_alpha: 0.0036840681931986645\n",
            "  reg_lambda: 0.7532480505730402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top 3 models per speed using all features"
      ],
      "metadata": {
        "id": "iMLl5xycdLJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read log lines\n",
        "with open(\"flaml_automl.log\", \"r\") as file:\n",
        "    log_lines = file.readlines()\n",
        "\n",
        "# Parse model entries\n",
        "data = []\n",
        "for line in log_lines:\n",
        "    try:\n",
        "        record = json.loads(line)\n",
        "        if \"validation_loss\" in record and \"learner\" in record:\n",
        "            learner = record[\"learner\"]\n",
        "            val_loss = record[\"validation_loss\"]\n",
        "            time = record.get(\"wall_clock_time\", None)\n",
        "            config = record.get(\"config\", {})\n",
        "            if time is not None:  # Filter only valid entries\n",
        "                data.append((learner, val_loss, time, config))\n",
        "    except json.JSONDecodeError:\n",
        "        continue\n",
        "\n",
        "# Create DataFrame\n",
        "df_trials = pd.DataFrame(data, columns=[\"learner\", \"val_loss\", \"wall_clock_time\", \"config\"])\n",
        "\n",
        "# Get top 3 by speed (lowest wall clock time)\n",
        "top3_speed = df_trials.sort_values(by=\"wall_clock_time\").head(3)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 3 models by speed (wall clock time):\")\n",
        "for idx, row in top3_speed.iterrows():\n",
        "    print(f\"\\nLearner: {row['learner']}\")\n",
        "    print(f\"Val Loss (RMSE): {row['val_loss']}\")\n",
        "    print(f\"Wall Clock Time: {row['wall_clock_time']}\")\n",
        "    print(\"Config:\")\n",
        "    for k, v in row['config'].items():\n",
        "        print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFxNhMFeazTN",
        "outputId": "a9ec2ad4-31ce-43d3-bcd1-6b5799d89a0e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 models by speed (wall clock time):\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 226.13949803386222\n",
            "Wall Clock Time: 0.5328385829925537\n",
            "Config:\n",
            "  n_estimators: 4\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 20\n",
            "  learning_rate: 0.09999999999999995\n",
            "  log_max_bin: 8\n",
            "  colsample_bytree: 1.0\n",
            "  reg_alpha: 0.0009765625\n",
            "  reg_lambda: 1.0\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 184.07472472034402\n",
            "Wall Clock Time: 1.4764113426208496\n",
            "Config:\n",
            "  n_estimators: 4\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 12\n",
            "  learning_rate: 0.26770501231052046\n",
            "  log_max_bin: 7\n",
            "  colsample_bytree: 1.0\n",
            "  reg_alpha: 0.001348364934537134\n",
            "  reg_lambda: 1.4442580148221913\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 148.45575068018815\n",
            "Wall Clock Time: 2.2854721546173096\n",
            "Config:\n",
            "  n_estimators: 11\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 9\n",
            "  learning_rate: 0.7260594590615893\n",
            "  log_max_bin: 9\n",
            "  colsample_bytree: 0.9285002286474459\n",
            "  reg_alpha: 0.0036840681931986645\n",
            "  reg_lambda: 0.7532480505730402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top 3 models per speed score using only the top features"
      ],
      "metadata": {
        "id": "w3P8u6jGeEoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "# Read log lines\n",
        "with open(\"flaml_automl_top3.log\", \"r\") as file:\n",
        "    log_lines = file.readlines()\n",
        "\n",
        "# Parse model entries\n",
        "data = []\n",
        "for line in log_lines:\n",
        "    try:\n",
        "        record = json.loads(line)\n",
        "        if \"validation_loss\" in record and \"learner\" in record:\n",
        "            learner = record[\"learner\"]\n",
        "            val_loss = record[\"validation_loss\"]\n",
        "            time = record.get(\"wall_clock_time\", None)\n",
        "            config = record.get(\"config\", {})\n",
        "            if time is not None:\n",
        "                data.append((learner, val_loss, time, config))\n",
        "    except json.JSONDecodeError:\n",
        "        continue\n",
        "\n",
        "# Create DataFrame\n",
        "df_trials = pd.DataFrame(data, columns=[\"learner\", \"val_loss\", \"wall_clock_time\", \"config\"])\n",
        "\n",
        "# Get top 3 by speed (lowest wall clock time)\n",
        "top3 = df_trials.sort_values(by=\"wall_clock_time\").head(3)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 3 models by speed using only the top 3 features:\")\n",
        "for idx, row in top3.iterrows():\n",
        "    print(f\"\\nLearner: {row['learner']}\")\n",
        "    print(f\"Val Loss (RMSE): {row['val_loss']}\")\n",
        "    print(f\"Wall Clock Time: {row['wall_clock_time']}\")\n",
        "    print(\"Config:\")\n",
        "    for k, v in row['config'].items():\n",
        "        print(f\"  {k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlKjAY4rdZN0",
        "outputId": "c03d2245-e7a4-4a03-8fab-5c73abd194c4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 models by speed using only the top 3 features:\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 268.1706210848114\n",
            "Wall Clock Time: 0.14544463157653809\n",
            "Config:\n",
            "  n_estimators: 4\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 20\n",
            "  learning_rate: 0.09999999999999995\n",
            "  log_max_bin: 8\n",
            "  colsample_bytree: 1.0\n",
            "  reg_alpha: 0.0009765625\n",
            "  reg_lambda: 1.0\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 261.53183392834137\n",
            "Wall Clock Time: 0.4026212692260742\n",
            "Config:\n",
            "  n_estimators: 4\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 12\n",
            "  learning_rate: 0.26770501231052046\n",
            "  log_max_bin: 7\n",
            "  colsample_bytree: 1.0\n",
            "  reg_alpha: 0.001348364934537134\n",
            "  reg_lambda: 1.4442580148221913\n",
            "\n",
            "Learner: lgbm\n",
            "Val Loss (RMSE): 257.1304090799774\n",
            "Wall Clock Time: 0.7351562976837158\n",
            "Config:\n",
            "  n_estimators: 11\n",
            "  num_leaves: 4\n",
            "  min_child_samples: 9\n",
            "  learning_rate: 0.7260594590615893\n",
            "  log_max_bin: 9\n",
            "  colsample_bytree: 0.9285002286474459\n",
            "  reg_alpha: 0.0036840681931986645\n",
            "  reg_lambda: 0.7532480505730402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How does the top models compare to your previously developed model (assignments 1 and 2) in terms of validation score and speed?"
      ],
      "metadata": {
        "id": "bpS-WSlhjMNv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **AutoML (FLAML) Top Model (lowest RMSE)**\n",
        "\n",
        "* **Learner:** `lgbm`\n",
        "* **Validation RMSE:** **137.89**\n",
        "* **Training Time (Wall Clock):** **60.34 sec**\n",
        "\n",
        "#### **Assignment 2 (Feature Store + MLflow)**\n",
        "\n",
        "* **Model:** `rf-model` (Random Forest)\n",
        "* **Validation RMSE:** **178.85**\n",
        "* **R²:** **0.589**\n",
        "* **Training Time:** **5 sec**\n",
        "\n",
        "#### **Assignment 1 (Data Versioning)**\n",
        "\n",
        "* No RMSE\n",
        "* R² Instead\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Comparison Summary**\n",
        "\n",
        "| Model Source     | RMSE            | Speed                    |\n",
        "| ---------------- | --------------- | ------------------------ |\n",
        "| **FLAML AutoML** | **137.89**    | 60.34 sec             |\n",
        "| **Assignment 2** | 178.85        | **5 sec**              |\n",
        "| **Assignment 1** | R² Instead    | (Unmeasured, but fast) |\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusion**\n",
        "\n",
        "* **FLAML AutoML** gives the **best RMSE (137.89)**, indicating the most accurate model overall.\n",
        "* **Assignment 2** trains much **faster (5 sec)** but at the cost of **worse performance**.\n",
        "* **Assignment 1** training time is not available .\n",
        "\n"
      ],
      "metadata": {
        "id": "gcvaHJ82ipG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Is your platform AutoML no-code/low-code/full-code and why?"
      ],
      "metadata": {
        "id": "N_RAKJ1amopP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Low-code — because I used minimal code to run FLAML AutoML, which automatically selected, tuned, and evaluated models without manually coding each one."
      ],
      "metadata": {
        "id": "XFnwoOTymtlU"
      }
    }
  ]
}